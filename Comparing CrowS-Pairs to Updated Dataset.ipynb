{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "import math\n",
    "import torch\n",
    "import argparse\n",
    "import difflib\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "from transformers import AlbertTokenizer, AlbertForMaskedLM\n",
    "from transformers import RobertaTokenizer, RobertaForMaskedLM\n",
    "from transformers import XLMRobertaTokenizer, XLMRobertaForMaskedLM\n",
    "from transformers import DistilBertTokenizer, DistilBertForMaskedLM\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "# \n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "from crows_pairs_methods import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_models = [\n",
    "    'bert-base-cased',\n",
    "    'bert-base-uncased',\n",
    "    'bert-large-uncased',\n",
    "    'bert-large-cased',\n",
    "    'bert-base-multilingual-uncased',\n",
    "    'bert-base-multilingual-cased',\n",
    "    'allenai/scibert_scivocab_uncased',\n",
    "    'emilyalsentzer/Bio_ClinicalBERT',\n",
    "    'microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract',\n",
    "    'ProsusAI/finbert',\n",
    "    'nlpaueb/legal-bert-base-uncased',\n",
    "    'GroNLP/hateBERT',\n",
    "    'anferico/bert-for-patents',\n",
    "    'jackaduma/SecBERT'\n",
    "]\n",
    "\n",
    "ALBERT_models = [\n",
    "    'albert-base-v1',\n",
    "    'albert-base-v2'\n",
    "]\n",
    "\n",
    "ROBERTA_models = [\n",
    "    'roberta-base',\n",
    "    'distilroberta-base',\n",
    "    'roberta-large',\n",
    "    'huggingface/CodeBERTa-small-v1',\n",
    "    'climatebert/distilroberta-base-climate-f'\n",
    "]\n",
    "\n",
    "all_models = BERT_models + ALBERT_models + ROBERTA_models + ['xlm-roberta-base', 'distilbert-base-multilingual-cased']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_dictionary = {'models' : [],\n",
    "'metric_scores' : [],\n",
    "'stereotype_scores' : [],\n",
    "'antistereotype_scores' : []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 262/262 [11:34<00:00,  2.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            models  metric_scores  stereotype_scores  antistereotype_scores\n",
      "0  bert-base-cased          55.73              57.86                  52.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 262/262 [11:24<00:00,  2.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              models  metric_scores  stereotype_scores  antistereotype_scores\n",
      "0    bert-base-cased          55.73              57.86                  52.43\n",
      "1  bert-base-uncased          58.02              55.35                  62.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 262/262 [37:22<00:00,  8.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               models  metric_scores  stereotype_scores  antistereotype_scores\n",
      "0     bert-base-cased          55.73              57.86                  52.43\n",
      "1   bert-base-uncased          58.02              55.35                  62.14\n",
      "2  bert-large-uncased          55.34              54.72                  56.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 262/262 [38:27<00:00,  8.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               models  metric_scores  stereotype_scores  antistereotype_scores\n",
      "0     bert-base-cased          55.73              57.86                  52.43\n",
      "1   bert-base-uncased          58.02              55.35                  62.14\n",
      "2  bert-large-uncased          55.34              54.72                  56.31\n",
      "3    bert-large-cased          52.29              55.35                  47.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 262/262 [17:52<00:00,  4.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           models  metric_scores  stereotype_scores  \\\n",
      "0                 bert-base-cased          55.73              57.86   \n",
      "1               bert-base-uncased          58.02              55.35   \n",
      "2              bert-large-uncased          55.34              54.72   \n",
      "3                bert-large-cased          52.29              55.35   \n",
      "4  bert-base-multilingual-uncased          53.05              52.83   \n",
      "\n",
      "   antistereotype_scores  \n",
      "0                  52.43  \n",
      "1                  62.14  \n",
      "2                  56.31  \n",
      "3                  47.57  \n",
      "4                  53.40  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 262/262 [19:33<00:00,  4.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           models  metric_scores  stereotype_scores  \\\n",
      "0                 bert-base-cased          55.73              57.86   \n",
      "1               bert-base-uncased          58.02              55.35   \n",
      "2              bert-large-uncased          55.34              54.72   \n",
      "3                bert-large-cased          52.29              55.35   \n",
      "4  bert-base-multilingual-uncased          53.05              52.83   \n",
      "5    bert-base-multilingual-cased          45.04              46.54   \n",
      "\n",
      "   antistereotype_scores  \n",
      "0                  52.43  \n",
      "1                  62.14  \n",
      "2                  56.31  \n",
      "3                  47.57  \n",
      "4                  53.40  \n",
      "5                  42.72  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 262/262 [12:42<00:00,  2.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             models  metric_scores  stereotype_scores  \\\n",
      "0                   bert-base-cased          55.73              57.86   \n",
      "1                 bert-base-uncased          58.02              55.35   \n",
      "2                bert-large-uncased          55.34              54.72   \n",
      "3                  bert-large-cased          52.29              55.35   \n",
      "4    bert-base-multilingual-uncased          53.05              52.83   \n",
      "5      bert-base-multilingual-cased          45.04              46.54   \n",
      "6  allenai/scibert_scivocab_uncased          44.27              35.85   \n",
      "\n",
      "   antistereotype_scores  \n",
      "0                  52.43  \n",
      "1                  62.14  \n",
      "2                  56.31  \n",
      "3                  47.57  \n",
      "4                  53.40  \n",
      "5                  42.72  \n",
      "6                  57.28  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 262/262 [12:25<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             models  metric_scores  stereotype_scores  \\\n",
      "0                   bert-base-cased          55.73              57.86   \n",
      "1                 bert-base-uncased          58.02              55.35   \n",
      "2                bert-large-uncased          55.34              54.72   \n",
      "3                  bert-large-cased          52.29              55.35   \n",
      "4    bert-base-multilingual-uncased          53.05              52.83   \n",
      "5      bert-base-multilingual-cased          45.04              46.54   \n",
      "6  allenai/scibert_scivocab_uncased          44.27              35.85   \n",
      "7   emilyalsentzer/Bio_ClinicalBERT          50.00              48.43   \n",
      "\n",
      "   antistereotype_scores  \n",
      "0                  52.43  \n",
      "1                  62.14  \n",
      "2                  56.31  \n",
      "3                  47.57  \n",
      "4                  53.40  \n",
      "5                  42.72  \n",
      "6                  57.28  \n",
      "7                  52.43  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 262/262 [14:11<00:00,  3.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              models  metric_scores  \\\n",
      "0                                    bert-base-cased          55.73   \n",
      "1                                  bert-base-uncased          58.02   \n",
      "2                                 bert-large-uncased          55.34   \n",
      "3                                   bert-large-cased          52.29   \n",
      "4                     bert-base-multilingual-uncased          53.05   \n",
      "5                       bert-base-multilingual-cased          45.04   \n",
      "6                   allenai/scibert_scivocab_uncased          44.27   \n",
      "7                    emilyalsentzer/Bio_ClinicalBERT          50.00   \n",
      "8  microsoft/BiomedNLP-PubMedBERT-base-uncased-ab...          51.91   \n",
      "\n",
      "   stereotype_scores  antistereotype_scores  \n",
      "0              57.86                  52.43  \n",
      "1              55.35                  62.14  \n",
      "2              54.72                  56.31  \n",
      "3              55.35                  47.57  \n",
      "4              52.83                  53.40  \n",
      "5              46.54                  42.72  \n",
      "6              35.85                  57.28  \n",
      "7              48.43                  52.43  \n",
      "8              50.94                  53.40  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ProsusAI/finbert were not used when initializing BertForMaskedLM: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMaskedLM were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 262/262 [11:29<00:00,  2.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              models  metric_scores  \\\n",
      "0                                    bert-base-cased          55.73   \n",
      "1                                  bert-base-uncased          58.02   \n",
      "2                                 bert-large-uncased          55.34   \n",
      "3                                   bert-large-cased          52.29   \n",
      "4                     bert-base-multilingual-uncased          53.05   \n",
      "5                       bert-base-multilingual-cased          45.04   \n",
      "6                   allenai/scibert_scivocab_uncased          44.27   \n",
      "7                    emilyalsentzer/Bio_ClinicalBERT          50.00   \n",
      "8  microsoft/BiomedNLP-PubMedBERT-base-uncased-ab...          51.91   \n",
      "9                                   ProsusAI/finbert          49.24   \n",
      "\n",
      "   stereotype_scores  antistereotype_scores  \n",
      "0              57.86                  52.43  \n",
      "1              55.35                  62.14  \n",
      "2              54.72                  56.31  \n",
      "3              55.35                  47.57  \n",
      "4              52.83                  53.40  \n",
      "5              46.54                  42.72  \n",
      "6              35.85                  57.28  \n",
      "7              48.43                  52.43  \n",
      "8              50.94                  53.40  \n",
      "9              61.64                  30.10  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpaueb/legal-bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 262/262 [12:41<00:00,  2.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               models  metric_scores  \\\n",
      "0                                     bert-base-cased          55.73   \n",
      "1                                   bert-base-uncased          58.02   \n",
      "2                                  bert-large-uncased          55.34   \n",
      "3                                    bert-large-cased          52.29   \n",
      "4                      bert-base-multilingual-uncased          53.05   \n",
      "5                        bert-base-multilingual-cased          45.04   \n",
      "6                    allenai/scibert_scivocab_uncased          44.27   \n",
      "7                     emilyalsentzer/Bio_ClinicalBERT          50.00   \n",
      "8   microsoft/BiomedNLP-PubMedBERT-base-uncased-ab...          51.91   \n",
      "9                                    ProsusAI/finbert          49.24   \n",
      "10                    nlpaueb/legal-bert-base-uncased          51.53   \n",
      "\n",
      "    stereotype_scores  antistereotype_scores  \n",
      "0               57.86                  52.43  \n",
      "1               55.35                  62.14  \n",
      "2               54.72                  56.31  \n",
      "3               55.35                  47.57  \n",
      "4               52.83                  53.40  \n",
      "5               46.54                  42.72  \n",
      "6               35.85                  57.28  \n",
      "7               48.43                  52.43  \n",
      "8               50.94                  53.40  \n",
      "9               61.64                  30.10  \n",
      "10              50.31                  53.40  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 262/262 [11:18<00:00,  2.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               models  metric_scores  \\\n",
      "0                                     bert-base-cased          55.73   \n",
      "1                                   bert-base-uncased          58.02   \n",
      "2                                  bert-large-uncased          55.34   \n",
      "3                                    bert-large-cased          52.29   \n",
      "4                      bert-base-multilingual-uncased          53.05   \n",
      "5                        bert-base-multilingual-cased          45.04   \n",
      "6                    allenai/scibert_scivocab_uncased          44.27   \n",
      "7                     emilyalsentzer/Bio_ClinicalBERT          50.00   \n",
      "8   microsoft/BiomedNLP-PubMedBERT-base-uncased-ab...          51.91   \n",
      "9                                    ProsusAI/finbert          49.24   \n",
      "10                    nlpaueb/legal-bert-base-uncased          51.53   \n",
      "11                                    GroNLP/hateBERT          52.67   \n",
      "\n",
      "    stereotype_scores  antistereotype_scores  \n",
      "0               57.86                  52.43  \n",
      "1               55.35                  62.14  \n",
      "2               54.72                  56.31  \n",
      "3               55.35                  47.57  \n",
      "4               52.83                  53.40  \n",
      "5               46.54                  42.72  \n",
      "6               35.85                  57.28  \n",
      "7               48.43                  52.43  \n",
      "8               50.94                  53.40  \n",
      "9               61.64                  30.10  \n",
      "10              50.31                  53.40  \n",
      "11              49.69                  57.28  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at anferico/bert-for-patents were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 262/262 [37:41<00:00,  8.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               models  metric_scores  \\\n",
      "0                                     bert-base-cased          55.73   \n",
      "1                                   bert-base-uncased          58.02   \n",
      "2                                  bert-large-uncased          55.34   \n",
      "3                                    bert-large-cased          52.29   \n",
      "4                      bert-base-multilingual-uncased          53.05   \n",
      "5                        bert-base-multilingual-cased          45.04   \n",
      "6                    allenai/scibert_scivocab_uncased          44.27   \n",
      "7                     emilyalsentzer/Bio_ClinicalBERT          50.00   \n",
      "8   microsoft/BiomedNLP-PubMedBERT-base-uncased-ab...          51.91   \n",
      "9                                    ProsusAI/finbert          49.24   \n",
      "10                    nlpaueb/legal-bert-base-uncased          51.53   \n",
      "11                                    GroNLP/hateBERT          52.67   \n",
      "12                          anferico/bert-for-patents          45.42   \n",
      "\n",
      "    stereotype_scores  antistereotype_scores  \n",
      "0               57.86                  52.43  \n",
      "1               55.35                  62.14  \n",
      "2               54.72                  56.31  \n",
      "3               55.35                  47.57  \n",
      "4               52.83                  53.40  \n",
      "5               46.54                  42.72  \n",
      "6               35.85                  57.28  \n",
      "7               48.43                  52.43  \n",
      "8               50.94                  53.40  \n",
      "9               61.64                  30.10  \n",
      "10              50.31                  53.40  \n",
      "11              49.69                  57.28  \n",
      "12              45.28                  45.63  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 262/262 [09:09<00:00,  2.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               models  metric_scores  \\\n",
      "0                                     bert-base-cased          55.73   \n",
      "1                                   bert-base-uncased          58.02   \n",
      "2                                  bert-large-uncased          55.34   \n",
      "3                                    bert-large-cased          52.29   \n",
      "4                      bert-base-multilingual-uncased          53.05   \n",
      "5                        bert-base-multilingual-cased          45.04   \n",
      "6                    allenai/scibert_scivocab_uncased          44.27   \n",
      "7                     emilyalsentzer/Bio_ClinicalBERT          50.00   \n",
      "8   microsoft/BiomedNLP-PubMedBERT-base-uncased-ab...          51.91   \n",
      "9                                    ProsusAI/finbert          49.24   \n",
      "10                    nlpaueb/legal-bert-base-uncased          51.53   \n",
      "11                                    GroNLP/hateBERT          52.67   \n",
      "12                          anferico/bert-for-patents          45.42   \n",
      "13                                  jackaduma/SecBERT          46.56   \n",
      "\n",
      "    stereotype_scores  antistereotype_scores  \n",
      "0               57.86                  52.43  \n",
      "1               55.35                  62.14  \n",
      "2               54.72                  56.31  \n",
      "3               55.35                  47.57  \n",
      "4               52.83                  53.40  \n",
      "5               46.54                  42.72  \n",
      "6               35.85                  57.28  \n",
      "7               48.43                  52.43  \n",
      "8               50.94                  53.40  \n",
      "9               61.64                  30.10  \n",
      "10              50.31                  53.40  \n",
      "11              49.69                  57.28  \n",
      "12              45.28                  45.63  \n",
      "13              40.25                  56.31  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 262/262 [09:41<00:00,  2.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               models  metric_scores  \\\n",
      "0                                     bert-base-cased          55.73   \n",
      "1                                   bert-base-uncased          58.02   \n",
      "2                                  bert-large-uncased          55.34   \n",
      "3                                    bert-large-cased          52.29   \n",
      "4                      bert-base-multilingual-uncased          53.05   \n",
      "5                        bert-base-multilingual-cased          45.04   \n",
      "6                    allenai/scibert_scivocab_uncased          44.27   \n",
      "7                     emilyalsentzer/Bio_ClinicalBERT          50.00   \n",
      "8   microsoft/BiomedNLP-PubMedBERT-base-uncased-ab...          51.91   \n",
      "9                                    ProsusAI/finbert          49.24   \n",
      "10                    nlpaueb/legal-bert-base-uncased          51.53   \n",
      "11                                    GroNLP/hateBERT          52.67   \n",
      "12                          anferico/bert-for-patents          45.42   \n",
      "13                                  jackaduma/SecBERT          46.56   \n",
      "14                                     albert-base-v1          53.44   \n",
      "\n",
      "    stereotype_scores  antistereotype_scores  \n",
      "0               57.86                  52.43  \n",
      "1               55.35                  62.14  \n",
      "2               54.72                  56.31  \n",
      "3               55.35                  47.57  \n",
      "4               52.83                  53.40  \n",
      "5               46.54                  42.72  \n",
      "6               35.85                  57.28  \n",
      "7               48.43                  52.43  \n",
      "8               50.94                  53.40  \n",
      "9               61.64                  30.10  \n",
      "10              50.31                  53.40  \n",
      "11              49.69                  57.28  \n",
      "12              45.28                  45.63  \n",
      "13              40.25                  56.31  \n",
      "14              52.83                  54.37  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 262/262 [10:27<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               models  metric_scores  \\\n",
      "0                                     bert-base-cased          55.73   \n",
      "1                                   bert-base-uncased          58.02   \n",
      "2                                  bert-large-uncased          55.34   \n",
      "3                                    bert-large-cased          52.29   \n",
      "4                      bert-base-multilingual-uncased          53.05   \n",
      "5                        bert-base-multilingual-cased          45.04   \n",
      "6                    allenai/scibert_scivocab_uncased          44.27   \n",
      "7                     emilyalsentzer/Bio_ClinicalBERT          50.00   \n",
      "8   microsoft/BiomedNLP-PubMedBERT-base-uncased-ab...          51.91   \n",
      "9                                    ProsusAI/finbert          49.24   \n",
      "10                    nlpaueb/legal-bert-base-uncased          51.53   \n",
      "11                                    GroNLP/hateBERT          52.67   \n",
      "12                          anferico/bert-for-patents          45.42   \n",
      "13                                  jackaduma/SecBERT          46.56   \n",
      "14                                     albert-base-v1          53.44   \n",
      "15                                     albert-base-v2          54.20   \n",
      "\n",
      "    stereotype_scores  antistereotype_scores  \n",
      "0               57.86                  52.43  \n",
      "1               55.35                  62.14  \n",
      "2               54.72                  56.31  \n",
      "3               55.35                  47.57  \n",
      "4               52.83                  53.40  \n",
      "5               46.54                  42.72  \n",
      "6               35.85                  57.28  \n",
      "7               48.43                  52.43  \n",
      "8               50.94                  53.40  \n",
      "9               61.64                  30.10  \n",
      "10              50.31                  53.40  \n",
      "11              49.69                  57.28  \n",
      "12              45.28                  45.63  \n",
      "13              40.25                  56.31  \n",
      "14              52.83                  54.37  \n",
      "15              47.17                  65.05  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 262/262 [13:03<00:00,  2.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               models  metric_scores  \\\n",
      "0                                     bert-base-cased          55.73   \n",
      "1                                   bert-base-uncased          58.02   \n",
      "2                                  bert-large-uncased          55.34   \n",
      "3                                    bert-large-cased          52.29   \n",
      "4                      bert-base-multilingual-uncased          53.05   \n",
      "5                        bert-base-multilingual-cased          45.04   \n",
      "6                    allenai/scibert_scivocab_uncased          44.27   \n",
      "7                     emilyalsentzer/Bio_ClinicalBERT          50.00   \n",
      "8   microsoft/BiomedNLP-PubMedBERT-base-uncased-ab...          51.91   \n",
      "9                                    ProsusAI/finbert          49.24   \n",
      "10                    nlpaueb/legal-bert-base-uncased          51.53   \n",
      "11                                    GroNLP/hateBERT          52.67   \n",
      "12                          anferico/bert-for-patents          45.42   \n",
      "13                                  jackaduma/SecBERT          46.56   \n",
      "14                                     albert-base-v1          53.44   \n",
      "15                                     albert-base-v2          54.20   \n",
      "16                                       roberta-base          54.96   \n",
      "\n",
      "    stereotype_scores  antistereotype_scores  \n",
      "0               57.86                  52.43  \n",
      "1               55.35                  62.14  \n",
      "2               54.72                  56.31  \n",
      "3               55.35                  47.57  \n",
      "4               52.83                  53.40  \n",
      "5               46.54                  42.72  \n",
      "6               35.85                  57.28  \n",
      "7               48.43                  52.43  \n",
      "8               50.94                  53.40  \n",
      "9               61.64                  30.10  \n",
      "10              50.31                  53.40  \n",
      "11              49.69                  57.28  \n",
      "12              45.28                  45.63  \n",
      "13              40.25                  56.31  \n",
      "14              52.83                  54.37  \n",
      "15              47.17                  65.05  \n",
      "16              59.12                  48.54  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 262/262 [08:14<00:00,  1.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               models  metric_scores  \\\n",
      "0                                     bert-base-cased          55.73   \n",
      "1                                   bert-base-uncased          58.02   \n",
      "2                                  bert-large-uncased          55.34   \n",
      "3                                    bert-large-cased          52.29   \n",
      "4                      bert-base-multilingual-uncased          53.05   \n",
      "5                        bert-base-multilingual-cased          45.04   \n",
      "6                    allenai/scibert_scivocab_uncased          44.27   \n",
      "7                     emilyalsentzer/Bio_ClinicalBERT          50.00   \n",
      "8   microsoft/BiomedNLP-PubMedBERT-base-uncased-ab...          51.91   \n",
      "9                                    ProsusAI/finbert          49.24   \n",
      "10                    nlpaueb/legal-bert-base-uncased          51.53   \n",
      "11                                    GroNLP/hateBERT          52.67   \n",
      "12                          anferico/bert-for-patents          45.42   \n",
      "13                                  jackaduma/SecBERT          46.56   \n",
      "14                                     albert-base-v1          53.44   \n",
      "15                                     albert-base-v2          54.20   \n",
      "16                                       roberta-base          54.96   \n",
      "17                                 distilroberta-base          53.82   \n",
      "\n",
      "    stereotype_scores  antistereotype_scores  \n",
      "0               57.86                  52.43  \n",
      "1               55.35                  62.14  \n",
      "2               54.72                  56.31  \n",
      "3               55.35                  47.57  \n",
      "4               52.83                  53.40  \n",
      "5               46.54                  42.72  \n",
      "6               35.85                  57.28  \n",
      "7               48.43                  52.43  \n",
      "8               50.94                  53.40  \n",
      "9               61.64                  30.10  \n",
      "10              50.31                  53.40  \n",
      "11              49.69                  57.28  \n",
      "12              45.28                  45.63  \n",
      "13              40.25                  56.31  \n",
      "14              52.83                  54.37  \n",
      "15              47.17                  65.05  \n",
      "16              59.12                  48.54  \n",
      "17              60.38                  43.69  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 262/262 [38:27<00:00,  8.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               models  metric_scores  \\\n",
      "0                                     bert-base-cased          55.73   \n",
      "1                                   bert-base-uncased          58.02   \n",
      "2                                  bert-large-uncased          55.34   \n",
      "3                                    bert-large-cased          52.29   \n",
      "4                      bert-base-multilingual-uncased          53.05   \n",
      "5                        bert-base-multilingual-cased          45.04   \n",
      "6                    allenai/scibert_scivocab_uncased          44.27   \n",
      "7                     emilyalsentzer/Bio_ClinicalBERT          50.00   \n",
      "8   microsoft/BiomedNLP-PubMedBERT-base-uncased-ab...          51.91   \n",
      "9                                    ProsusAI/finbert          49.24   \n",
      "10                    nlpaueb/legal-bert-base-uncased          51.53   \n",
      "11                                    GroNLP/hateBERT          52.67   \n",
      "12                          anferico/bert-for-patents          45.42   \n",
      "13                                  jackaduma/SecBERT          46.56   \n",
      "14                                     albert-base-v1          53.44   \n",
      "15                                     albert-base-v2          54.20   \n",
      "16                                       roberta-base          54.96   \n",
      "17                                 distilroberta-base          53.82   \n",
      "18                                      roberta-large          51.91   \n",
      "\n",
      "    stereotype_scores  antistereotype_scores  \n",
      "0               57.86                  52.43  \n",
      "1               55.35                  62.14  \n",
      "2               54.72                  56.31  \n",
      "3               55.35                  47.57  \n",
      "4               52.83                  53.40  \n",
      "5               46.54                  42.72  \n",
      "6               35.85                  57.28  \n",
      "7               48.43                  52.43  \n",
      "8               50.94                  53.40  \n",
      "9               61.64                  30.10  \n",
      "10              50.31                  53.40  \n",
      "11              49.69                  57.28  \n",
      "12              45.28                  45.63  \n",
      "13              40.25                  56.31  \n",
      "14              52.83                  54.37  \n",
      "15              47.17                  65.05  \n",
      "16              59.12                  48.54  \n",
      "17              60.38                  43.69  \n",
      "18              55.97                  45.63  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 262/262 [09:40<00:00,  2.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               models  metric_scores  \\\n",
      "0                                     bert-base-cased          55.73   \n",
      "1                                   bert-base-uncased          58.02   \n",
      "2                                  bert-large-uncased          55.34   \n",
      "3                                    bert-large-cased          52.29   \n",
      "4                      bert-base-multilingual-uncased          53.05   \n",
      "5                        bert-base-multilingual-cased          45.04   \n",
      "6                    allenai/scibert_scivocab_uncased          44.27   \n",
      "7                     emilyalsentzer/Bio_ClinicalBERT          50.00   \n",
      "8   microsoft/BiomedNLP-PubMedBERT-base-uncased-ab...          51.91   \n",
      "9                                    ProsusAI/finbert          49.24   \n",
      "10                    nlpaueb/legal-bert-base-uncased          51.53   \n",
      "11                                    GroNLP/hateBERT          52.67   \n",
      "12                          anferico/bert-for-patents          45.42   \n",
      "13                                  jackaduma/SecBERT          46.56   \n",
      "14                                     albert-base-v1          53.44   \n",
      "15                                     albert-base-v2          54.20   \n",
      "16                                       roberta-base          54.96   \n",
      "17                                 distilroberta-base          53.82   \n",
      "18                                      roberta-large          51.91   \n",
      "19                     huggingface/CodeBERTa-small-v1          55.73   \n",
      "\n",
      "    stereotype_scores  antistereotype_scores  \n",
      "0               57.86                  52.43  \n",
      "1               55.35                  62.14  \n",
      "2               54.72                  56.31  \n",
      "3               55.35                  47.57  \n",
      "4               52.83                  53.40  \n",
      "5               46.54                  42.72  \n",
      "6               35.85                  57.28  \n",
      "7               48.43                  52.43  \n",
      "8               50.94                  53.40  \n",
      "9               61.64                  30.10  \n",
      "10              50.31                  53.40  \n",
      "11              49.69                  57.28  \n",
      "12              45.28                  45.63  \n",
      "13              40.25                  56.31  \n",
      "14              52.83                  54.37  \n",
      "15              47.17                  65.05  \n",
      "16              59.12                  48.54  \n",
      "17              60.38                  43.69  \n",
      "18              55.97                  45.63  \n",
      "19              50.94                  63.11  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 262/262 [08:12<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               models  metric_scores  \\\n",
      "0                                     bert-base-cased          55.73   \n",
      "1                                   bert-base-uncased          58.02   \n",
      "2                                  bert-large-uncased          55.34   \n",
      "3                                    bert-large-cased          52.29   \n",
      "4                      bert-base-multilingual-uncased          53.05   \n",
      "5                        bert-base-multilingual-cased          45.04   \n",
      "6                    allenai/scibert_scivocab_uncased          44.27   \n",
      "7                     emilyalsentzer/Bio_ClinicalBERT          50.00   \n",
      "8   microsoft/BiomedNLP-PubMedBERT-base-uncased-ab...          51.91   \n",
      "9                                    ProsusAI/finbert          49.24   \n",
      "10                    nlpaueb/legal-bert-base-uncased          51.53   \n",
      "11                                    GroNLP/hateBERT          52.67   \n",
      "12                          anferico/bert-for-patents          45.42   \n",
      "13                                  jackaduma/SecBERT          46.56   \n",
      "14                                     albert-base-v1          53.44   \n",
      "15                                     albert-base-v2          54.20   \n",
      "16                                       roberta-base          54.96   \n",
      "17                                 distilroberta-base          53.82   \n",
      "18                                      roberta-large          51.91   \n",
      "19                     huggingface/CodeBERTa-small-v1          55.73   \n",
      "20           climatebert/distilroberta-base-climate-f          51.15   \n",
      "\n",
      "    stereotype_scores  antistereotype_scores  \n",
      "0               57.86                  52.43  \n",
      "1               55.35                  62.14  \n",
      "2               54.72                  56.31  \n",
      "3               55.35                  47.57  \n",
      "4               52.83                  53.40  \n",
      "5               46.54                  42.72  \n",
      "6               35.85                  57.28  \n",
      "7               48.43                  52.43  \n",
      "8               50.94                  53.40  \n",
      "9               61.64                  30.10  \n",
      "10              50.31                  53.40  \n",
      "11              49.69                  57.28  \n",
      "12              45.28                  45.63  \n",
      "13              40.25                  56.31  \n",
      "14              52.83                  54.37  \n",
      "15              47.17                  65.05  \n",
      "16              59.12                  48.54  \n",
      "17              60.38                  43.69  \n",
      "18              55.97                  45.63  \n",
      "19              50.94                  63.11  \n",
      "20              50.31                  52.43  \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'XMLRobertaTokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-9978718f920f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRobertaForMaskedLM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'xlm-roberta-base'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXMLRobertaTokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXMLRobertaForMaskedLM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'distilbert-base-multilingual-cased'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'XMLRobertaTokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "for model_name in all_models:\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    # load data into panda DataFrame\n",
    "    df_data = read_data(\"fixed_data.csv\")\n",
    "\n",
    "    # Filtering to Disability Data\n",
    "    df_data = df_data[df_data['bias_type']=='gender']\n",
    "    \n",
    "    # supported masked language models (using bert)\n",
    "    if model_name in BERT_models:\n",
    "        tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "        model = BertForMaskedLM.from_pretrained(model_name)\n",
    "    elif model_name in ALBERT_models:\n",
    "        tokenizer = AlbertTokenizer.from_pretrained(model_name)\n",
    "        model = AlbertForMaskedLM.from_pretrained(model_name)\n",
    "    elif model_name in ROBERTA_models:\n",
    "        tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "        model = RobertaForMaskedLM.from_pretrained(model_name)\n",
    "    elif model_name == 'xlm-roberta-base':\n",
    "        tokenizer = XMLRobertaTokenizer.from_pretrained(model_name)\n",
    "        model = XMLRobertaForMaskedLM.from_pretrained(model_name)\n",
    "    elif model_name == 'distilbert-base-multilingual-cased':\n",
    "        tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "        model = DistilBertForMaskedLM.from_pretrained(model_name)\n",
    "        \n",
    "    mask_token = tokenizer.mask_token\n",
    "    log_softmax = torch.nn.LogSoftmax(dim=0)\n",
    "    vocab = tokenizer.get_vocab()\n",
    "    with open(\"bert\" + \".vocab\", \"w\") as f:\n",
    "        f.write(json.dumps(vocab))\n",
    "\n",
    "    lm = {\"model\": model,\n",
    "          \"tokenizer\": tokenizer,\n",
    "          \"mask_token\": mask_token,\n",
    "          \"log_softmax\": log_softmax,\n",
    "          \"uncased\": True\n",
    "    }\n",
    "\n",
    "    # score each sentence. \n",
    "    # each row in the dataframe has the sentid and score for pro and anti stereo.\n",
    "    df_score = pd.DataFrame(columns=['sent_more', 'sent_less', \n",
    "                                     'sent_more_score', 'sent_less_score',\n",
    "                                     'score', 'stereo_antistereo', 'bias_type'], dtype=object)\n",
    "    \n",
    "    total_stereo, total_antistereo = 0, 0\n",
    "    stereo_score, antistereo_score = 0, 0\n",
    "\n",
    "    N = 0\n",
    "    neutral = 0\n",
    "    total = len(df_data.index)\n",
    "    with tqdm(total=total) as pbar:\n",
    "        for index, data in df_data.iterrows():\n",
    "            direction = data['direction']\n",
    "            bias = data['bias_type']\n",
    "            score = mask_unigram(data, lm)\n",
    "\n",
    "            for stype in score.keys():\n",
    "                score[stype] = round(score[stype], 3)\n",
    "\n",
    "            N += 1\n",
    "            pair_score = 0\n",
    "            pbar.update(1)\n",
    "            if score['sent1_score'] == score['sent2_score']:\n",
    "                neutral += 1\n",
    "            else:\n",
    "                if direction == 'stereo':\n",
    "                    total_stereo += 1\n",
    "                    if score['sent1_score'] > score['sent2_score']:\n",
    "                        stereo_score += 1\n",
    "                        pair_score = 1\n",
    "                elif direction == 'antistereo':\n",
    "                    total_antistereo += 1\n",
    "                    if score['sent2_score'] > score['sent1_score']:\n",
    "                        antistereo_score += 1\n",
    "                        pair_score = 1\n",
    "\n",
    "            sent_more, sent_less = '', ''\n",
    "            if direction == 'stereo':\n",
    "                sent_more = data['sent1']\n",
    "                sent_less = data['sent2']\n",
    "                sent_more_score = score['sent1_score']\n",
    "                sent_less_score = score['sent2_score']\n",
    "            else:\n",
    "                sent_more = data['sent2']\n",
    "                sent_less = data['sent1']\n",
    "                sent_more_score = score['sent2_score']\n",
    "                sent_less_score = score['sent1_score']\n",
    "\n",
    "            df_score = df_score.append({'sent_more': sent_more,\n",
    "                                        'sent_less': sent_less,\n",
    "                                        'sent_more_score': sent_more_score,\n",
    "                                        'sent_less_score': sent_less_score,\n",
    "                                        'score': pair_score,\n",
    "                                        'stereo_antistereo': direction,\n",
    "                                        'bias_type': bias\n",
    "                                      }, ignore_index=True)\n",
    "    \n",
    "    dataframe_dictionary['models'].append(model_name)\n",
    "    dataframe_dictionary['metric_scores'].append(round((stereo_score + antistereo_score) / N * 100, 2))\n",
    "    dataframe_dictionary['stereotype_scores'].append(round(stereo_score  / total_stereo * 100, 2))\n",
    "    dataframe_dictionary['antistereotype_scores'].append(round(antistereo_score  / total_antistereo * 100, 2))\n",
    "    \n",
    "    print(pd.DataFrame(dataframe_dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_dataframe = {\n",
    "    'models' : all_models,\n",
    "    'metric_scores' : [55.73, 58.02, 55.34, \n",
    "                       52.29, 53.05, 45.04, \n",
    "                       57.25, 44.27, 50, \n",
    "                       51.91, 45.8, 51.53, \n",
    "                       52.67, 45.42, 46.56, \n",
    "                       53.44, 54.2, 54.96, \n",
    "                       53.82, 51.91, 50.38,\n",
    "                       55.73, 51.15],\n",
    "    'stereotype_scores' : [57.86, 55.35, 54.72, \n",
    "                           55.35, 52.83, 46.54, \n",
    "                           65.41, 35.85, 48.43, \n",
    "                           50.94, 44.65, 50.31, \n",
    "                           49.69, 45.28, 40.25, \n",
    "                           52.83, 47.17, 59.12, \n",
    "                           60.38, 55.97, 50.94, \n",
    "                           50.94, 50.31],\n",
    "    'antistereotype_scores' : [52.43, 62.14, 56.31, \n",
    "                               47.57, 53.4, 42.72, \n",
    "                               44.66, 57.28, 52.43, \n",
    "                               53.4, 47.57, 53.4, \n",
    "                               57.28, 45.63, 56.31, \n",
    "                               54.37, 65.05, 48.54, \n",
    "                               43.69, 45.63, 49.51, \n",
    "                               63.11, 52.43]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 262/262 [1:14:50<00:00, 17.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               models  metric_scores  \\\n",
      "0                                     bert-base-cased          55.73   \n",
      "1                                   bert-base-uncased          58.02   \n",
      "2                                  bert-large-uncased          55.34   \n",
      "3                                    bert-large-cased          52.29   \n",
      "4                      bert-base-multilingual-uncased          53.05   \n",
      "5                        bert-base-multilingual-cased          45.04   \n",
      "6                    allenai/scibert_scivocab_uncased          44.27   \n",
      "7                     emilyalsentzer/Bio_ClinicalBERT          50.00   \n",
      "8   microsoft/BiomedNLP-PubMedBERT-base-uncased-ab...          51.91   \n",
      "9                                    ProsusAI/finbert          49.24   \n",
      "10                    nlpaueb/legal-bert-base-uncased          51.53   \n",
      "11                                    GroNLP/hateBERT          52.67   \n",
      "12                          anferico/bert-for-patents          45.42   \n",
      "13                                  jackaduma/SecBERT          46.56   \n",
      "14                                     albert-base-v1          53.44   \n",
      "15                                     albert-base-v2          54.20   \n",
      "16                                       roberta-base          54.96   \n",
      "17                                 distilroberta-base          53.82   \n",
      "18                                      roberta-large          51.91   \n",
      "19                     huggingface/CodeBERTa-small-v1          55.73   \n",
      "20           climatebert/distilroberta-base-climate-f          51.15   \n",
      "21                                   xlm-roberta-base          50.38   \n",
      "\n",
      "    stereotype_scores  antistereotype_scores  \n",
      "0               57.86                  52.43  \n",
      "1               55.35                  62.14  \n",
      "2               54.72                  56.31  \n",
      "3               55.35                  47.57  \n",
      "4               52.83                  53.40  \n",
      "5               46.54                  42.72  \n",
      "6               35.85                  57.28  \n",
      "7               48.43                  52.43  \n",
      "8               50.94                  53.40  \n",
      "9               61.64                  30.10  \n",
      "10              50.31                  53.40  \n",
      "11              49.69                  57.28  \n",
      "12              45.28                  45.63  \n",
      "13              40.25                  56.31  \n",
      "14              52.83                  54.37  \n",
      "15              47.17                  65.05  \n",
      "16              59.12                  48.54  \n",
      "17              60.38                  43.69  \n",
      "18              55.97                  45.63  \n",
      "19              50.94                  63.11  \n",
      "20              50.31                  52.43  \n",
      "21              50.94                  49.51  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 262/262 [21:11<00:00,  4.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               models  metric_scores  \\\n",
      "0                                     bert-base-cased          55.73   \n",
      "1                                   bert-base-uncased          58.02   \n",
      "2                                  bert-large-uncased          55.34   \n",
      "3                                    bert-large-cased          52.29   \n",
      "4                      bert-base-multilingual-uncased          53.05   \n",
      "5                        bert-base-multilingual-cased          45.04   \n",
      "6                    allenai/scibert_scivocab_uncased          44.27   \n",
      "7                     emilyalsentzer/Bio_ClinicalBERT          50.00   \n",
      "8   microsoft/BiomedNLP-PubMedBERT-base-uncased-ab...          51.91   \n",
      "9                                    ProsusAI/finbert          49.24   \n",
      "10                    nlpaueb/legal-bert-base-uncased          51.53   \n",
      "11                                    GroNLP/hateBERT          52.67   \n",
      "12                          anferico/bert-for-patents          45.42   \n",
      "13                                  jackaduma/SecBERT          46.56   \n",
      "14                                     albert-base-v1          53.44   \n",
      "15                                     albert-base-v2          54.20   \n",
      "16                                       roberta-base          54.96   \n",
      "17                                 distilroberta-base          53.82   \n",
      "18                                      roberta-large          51.91   \n",
      "19                     huggingface/CodeBERTa-small-v1          55.73   \n",
      "20           climatebert/distilroberta-base-climate-f          51.15   \n",
      "21                                   xlm-roberta-base          50.38   \n",
      "22                 distilbert-base-multilingual-cased          46.56   \n",
      "\n",
      "    stereotype_scores  antistereotype_scores  \n",
      "0               57.86                  52.43  \n",
      "1               55.35                  62.14  \n",
      "2               54.72                  56.31  \n",
      "3               55.35                  47.57  \n",
      "4               52.83                  53.40  \n",
      "5               46.54                  42.72  \n",
      "6               35.85                  57.28  \n",
      "7               48.43                  52.43  \n",
      "8               50.94                  53.40  \n",
      "9               61.64                  30.10  \n",
      "10              50.31                  53.40  \n",
      "11              49.69                  57.28  \n",
      "12              45.28                  45.63  \n",
      "13              40.25                  56.31  \n",
      "14              52.83                  54.37  \n",
      "15              47.17                  65.05  \n",
      "16              59.12                  48.54  \n",
      "17              60.38                  43.69  \n",
      "18              55.97                  45.63  \n",
      "19              50.94                  63.11  \n",
      "20              50.31                  52.43  \n",
      "21              50.94                  49.51  \n",
      "22              43.40                  51.46  \n"
     ]
    }
   ],
   "source": [
    "for model_name in ['xlm-roberta-base', 'distilbert-base-multilingual-cased']:\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    # load data into panda DataFrame\n",
    "    df_data = read_data(\"fixed_data.csv\")\n",
    "\n",
    "    # Filtering to Disability Data\n",
    "    df_data = df_data[df_data['bias_type']=='gender']\n",
    "    \n",
    "    # supported masked language models (using bert)\n",
    "    if model_name in BERT_models:\n",
    "        tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "        model = BertForMaskedLM.from_pretrained(model_name)\n",
    "    elif model_name in ALBERT_models:\n",
    "        tokenizer = AlbertTokenizer.from_pretrained(model_name)\n",
    "        model = AlbertForMaskedLM.from_pretrained(model_name)\n",
    "    elif model_name in ROBERTA_models:\n",
    "        tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "        model = RobertaForMaskedLM.from_pretrained(model_name)\n",
    "    elif model_name == 'xlm-roberta-base':\n",
    "        tokenizer = XLMRobertaTokenizer.from_pretrained(model_name)\n",
    "        model = XLMRobertaForMaskedLM.from_pretrained(model_name)\n",
    "    elif model_name == 'distilbert-base-multilingual-cased':\n",
    "        tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "        model = DistilBertForMaskedLM.from_pretrained(model_name)\n",
    "        \n",
    "    mask_token = tokenizer.mask_token\n",
    "    log_softmax = torch.nn.LogSoftmax(dim=0)\n",
    "    vocab = tokenizer.get_vocab()\n",
    "    with open(\"bert\" + \".vocab\", \"w\") as f:\n",
    "        f.write(json.dumps(vocab))\n",
    "\n",
    "    lm = {\"model\": model,\n",
    "          \"tokenizer\": tokenizer,\n",
    "          \"mask_token\": mask_token,\n",
    "          \"log_softmax\": log_softmax,\n",
    "          \"uncased\": True\n",
    "    }\n",
    "\n",
    "    # score each sentence. \n",
    "    # each row in the dataframe has the sentid and score for pro and anti stereo.\n",
    "    df_score = pd.DataFrame(columns=['sent_more', 'sent_less', \n",
    "                                     'sent_more_score', 'sent_less_score',\n",
    "                                     'score', 'stereo_antistereo', 'bias_type'], dtype=object)\n",
    "    \n",
    "    total_stereo, total_antistereo = 0, 0\n",
    "    stereo_score, antistereo_score = 0, 0\n",
    "\n",
    "    N = 0\n",
    "    neutral = 0\n",
    "    total = len(df_data.index)\n",
    "    with tqdm(total=total) as pbar:\n",
    "        for index, data in df_data.iterrows():\n",
    "            direction = data['direction']\n",
    "            bias = data['bias_type']\n",
    "            score = mask_unigram(data, lm)\n",
    "\n",
    "            for stype in score.keys():\n",
    "                score[stype] = round(score[stype], 3)\n",
    "\n",
    "            N += 1\n",
    "            pair_score = 0\n",
    "            pbar.update(1)\n",
    "            if score['sent1_score'] == score['sent2_score']:\n",
    "                neutral += 1\n",
    "            else:\n",
    "                if direction == 'stereo':\n",
    "                    total_stereo += 1\n",
    "                    if score['sent1_score'] > score['sent2_score']:\n",
    "                        stereo_score += 1\n",
    "                        pair_score = 1\n",
    "                elif direction == 'antistereo':\n",
    "                    total_antistereo += 1\n",
    "                    if score['sent2_score'] > score['sent1_score']:\n",
    "                        antistereo_score += 1\n",
    "                        pair_score = 1\n",
    "\n",
    "            sent_more, sent_less = '', ''\n",
    "            if direction == 'stereo':\n",
    "                sent_more = data['sent1']\n",
    "                sent_less = data['sent2']\n",
    "                sent_more_score = score['sent1_score']\n",
    "                sent_less_score = score['sent2_score']\n",
    "            else:\n",
    "                sent_more = data['sent2']\n",
    "                sent_less = data['sent1']\n",
    "                sent_more_score = score['sent2_score']\n",
    "                sent_less_score = score['sent1_score']\n",
    "\n",
    "            df_score = df_score.append({'sent_more': sent_more,\n",
    "                                        'sent_less': sent_less,\n",
    "                                        'sent_more_score': sent_more_score,\n",
    "                                        'sent_less_score': sent_less_score,\n",
    "                                        'score': pair_score,\n",
    "                                        'stereo_antistereo': direction,\n",
    "                                        'bias_type': bias\n",
    "                                      }, ignore_index=True)\n",
    "    \n",
    "    dataframe_dictionary['models'].append(model_name)\n",
    "    dataframe_dictionary['metric_scores'].append(round((stereo_score + antistereo_score) / N * 100, 2))\n",
    "    dataframe_dictionary['stereotype_scores'].append(round(stereo_score  / total_stereo * 100, 2))\n",
    "    dataframe_dictionary['antistereotype_scores'].append(round(antistereo_score  / total_antistereo * 100, 2))\n",
    "    \n",
    "    print(pd.DataFrame(dataframe_dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_dataframe = {\n",
    "    'models' : all_models,\n",
    "    'metric_scores' : [55.73, 58.02, 55.34, \n",
    "                       52.29, 53.05, 45.04, \n",
    "                       44.27, 50, 51.91, \n",
    "                       49.24, 51.53, 52.67, \n",
    "                       45.42, 46.56, 53.44, \n",
    "                       54.2, 54.96, 53.82, \n",
    "                       51.91, 55.73, 51.15, \n",
    "                       50.38, 46.56],\n",
    "    'stereotype_scores' : [57.86, 55.35, 54.72, \n",
    "                           55.35, 52.83, 46.54, \n",
    "                           35.85, 48.43, 50.94, \n",
    "                           61.64, 50.31, 49.69, \n",
    "                           45.28, 40.25, 52.83, \n",
    "                           47.17, 59.12, 60.38, \n",
    "                           55.97, 50.94, 50.31, \n",
    "                           50.94, 43.40],\n",
    "    'antistereotype_scores' : [52.43, 62.14, 56.31, \n",
    "                               47.57, 53.4, 42.72, \n",
    "                               57.28, 52.43, 53.4, \n",
    "                               30.10, 53.4, 57.28, \n",
    "                               45.63, 56.31, 54.37, \n",
    "                               65.05, 48.54, 43.69, \n",
    "                               45.63, 63.11, 52.43, \n",
    "                               49.51, 51.46]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>metric_scores</th>\n",
       "      <th>stereotype_scores</th>\n",
       "      <th>antistereotype_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>bert-base-cased</td>\n",
       "      <td>55.73</td>\n",
       "      <td>57.86</td>\n",
       "      <td>52.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>58.02</td>\n",
       "      <td>55.35</td>\n",
       "      <td>62.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>bert-large-uncased</td>\n",
       "      <td>55.34</td>\n",
       "      <td>54.72</td>\n",
       "      <td>56.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>bert-large-cased</td>\n",
       "      <td>52.29</td>\n",
       "      <td>55.35</td>\n",
       "      <td>47.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>bert-base-multilingual-uncased</td>\n",
       "      <td>53.05</td>\n",
       "      <td>52.83</td>\n",
       "      <td>53.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>bert-base-multilingual-cased</td>\n",
       "      <td>45.04</td>\n",
       "      <td>46.54</td>\n",
       "      <td>42.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>allenai/scibert_scivocab_uncased</td>\n",
       "      <td>44.27</td>\n",
       "      <td>35.85</td>\n",
       "      <td>57.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>emilyalsentzer/Bio_ClinicalBERT</td>\n",
       "      <td>50.00</td>\n",
       "      <td>48.43</td>\n",
       "      <td>52.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>microsoft/BiomedNLP-PubMedBERT-base-uncased-ab...</td>\n",
       "      <td>51.91</td>\n",
       "      <td>50.94</td>\n",
       "      <td>53.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>ProsusAI/finbert</td>\n",
       "      <td>49.24</td>\n",
       "      <td>61.64</td>\n",
       "      <td>30.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>nlpaueb/legal-bert-base-uncased</td>\n",
       "      <td>51.53</td>\n",
       "      <td>50.31</td>\n",
       "      <td>53.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>GroNLP/hateBERT</td>\n",
       "      <td>52.67</td>\n",
       "      <td>49.69</td>\n",
       "      <td>57.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>anferico/bert-for-patents</td>\n",
       "      <td>45.42</td>\n",
       "      <td>45.28</td>\n",
       "      <td>45.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>jackaduma/SecBERT</td>\n",
       "      <td>46.56</td>\n",
       "      <td>40.25</td>\n",
       "      <td>56.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>albert-base-v1</td>\n",
       "      <td>53.44</td>\n",
       "      <td>52.83</td>\n",
       "      <td>54.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>albert-base-v2</td>\n",
       "      <td>54.20</td>\n",
       "      <td>47.17</td>\n",
       "      <td>65.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>54.96</td>\n",
       "      <td>59.12</td>\n",
       "      <td>48.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>distilroberta-base</td>\n",
       "      <td>53.82</td>\n",
       "      <td>60.38</td>\n",
       "      <td>43.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>roberta-large</td>\n",
       "      <td>51.91</td>\n",
       "      <td>55.97</td>\n",
       "      <td>45.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>huggingface/CodeBERTa-small-v1</td>\n",
       "      <td>55.73</td>\n",
       "      <td>50.94</td>\n",
       "      <td>63.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>climatebert/distilroberta-base-climate-f</td>\n",
       "      <td>51.15</td>\n",
       "      <td>50.31</td>\n",
       "      <td>52.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>50.38</td>\n",
       "      <td>50.94</td>\n",
       "      <td>49.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>distilbert-base-multilingual-cased</td>\n",
       "      <td>46.56</td>\n",
       "      <td>43.40</td>\n",
       "      <td>51.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               models  metric_scores  \\\n",
       "0                                     bert-base-cased          55.73   \n",
       "1                                   bert-base-uncased          58.02   \n",
       "2                                  bert-large-uncased          55.34   \n",
       "3                                    bert-large-cased          52.29   \n",
       "4                      bert-base-multilingual-uncased          53.05   \n",
       "5                        bert-base-multilingual-cased          45.04   \n",
       "6                    allenai/scibert_scivocab_uncased          44.27   \n",
       "7                     emilyalsentzer/Bio_ClinicalBERT          50.00   \n",
       "8   microsoft/BiomedNLP-PubMedBERT-base-uncased-ab...          51.91   \n",
       "9                                    ProsusAI/finbert          49.24   \n",
       "10                    nlpaueb/legal-bert-base-uncased          51.53   \n",
       "11                                    GroNLP/hateBERT          52.67   \n",
       "12                          anferico/bert-for-patents          45.42   \n",
       "13                                  jackaduma/SecBERT          46.56   \n",
       "14                                     albert-base-v1          53.44   \n",
       "15                                     albert-base-v2          54.20   \n",
       "16                                       roberta-base          54.96   \n",
       "17                                 distilroberta-base          53.82   \n",
       "18                                      roberta-large          51.91   \n",
       "19                     huggingface/CodeBERTa-small-v1          55.73   \n",
       "20           climatebert/distilroberta-base-climate-f          51.15   \n",
       "21                                   xlm-roberta-base          50.38   \n",
       "22                 distilbert-base-multilingual-cased          46.56   \n",
       "\n",
       "    stereotype_scores  antistereotype_scores  \n",
       "0               57.86                  52.43  \n",
       "1               55.35                  62.14  \n",
       "2               54.72                  56.31  \n",
       "3               55.35                  47.57  \n",
       "4               52.83                  53.40  \n",
       "5               46.54                  42.72  \n",
       "6               35.85                  57.28  \n",
       "7               48.43                  52.43  \n",
       "8               50.94                  53.40  \n",
       "9               61.64                  30.10  \n",
       "10              50.31                  53.40  \n",
       "11              49.69                  57.28  \n",
       "12              45.28                  45.63  \n",
       "13              40.25                  56.31  \n",
       "14              52.83                  54.37  \n",
       "15              47.17                  65.05  \n",
       "16              59.12                  48.54  \n",
       "17              60.38                  43.69  \n",
       "18              55.97                  45.63  \n",
       "19              50.94                  63.11  \n",
       "20              50.31                  52.43  \n",
       "21              50.94                  49.51  \n",
       "22              43.40                  51.46  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gender_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost every model's scores have remain unchanged, except for <i>ProsusAI/finbert</i> and <i>distilbert-base-multilingual-cased</i>. These two models had changes in all three scores (metric, stereotype and anti-stereotype). These changes are shown below:\n",
    "\n",
    "<b><u>ProsusAI/finbert</u></b>\n",
    "* Metric Score:\n",
    "    * 45.80 (+7.5%) -> 49.24\n",
    "* Stereotype Score:\n",
    "    * 44.65 (+38%) -> 61.64\n",
    "* Anti-stereotype Score:\n",
    "    * 47.57 (-36.7%) -> 30.10\n",
    "    \n",
    "<b><u>distilbert-base-multilingual-cased</u></b>\n",
    "* Metric Score\n",
    "    * 57.25 (-18.7%) -> 46.56\n",
    "* Stereotype Score\n",
    "    * 65.41 (-33.6%) -> 43.40\n",
    "* Antistereotype Score\n",
    "    * 44.66 (+15.2%) -> 51.46\n",
    "    \n",
    "You can see from the above figures that these models have been heavily affected by the changes made to the CrowS-Pairs dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
